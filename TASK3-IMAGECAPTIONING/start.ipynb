{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tkinter import Tk, filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = hub.load(\"./mobilenet-v2-tensorflow1-openimages-v4-ssd-mobilenet-v2-v1\").signatures[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorcodes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawbox(image,ymin,xmin,ymax,xmax,namewithscore,color):\n",
    "    im_height, im_width, _  = image.shape\n",
    "    left,top,right,bottom = int(xmin*im_width), int(ymin*im_height), int(xmax*im_width),int(ymax*im_height)\n",
    "    cv2.rectangle(image,(left,top),(right,bottom),color = color,thickness = 4)\n",
    "    FONT_SCALE = 5e-3\n",
    "    THICKNESS_SCALE = 4e-3\n",
    "    width = right-left\n",
    "    height = bottom-top\n",
    "    TEXT_Y_OFFSET_SCALE = 1e-2\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (left,top- int(height * 6e-2)),\n",
    "        (right,top),\n",
    "        color = color,\n",
    "        thickness = -1\n",
    "        \n",
    "    )\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        namewithscore,\n",
    "        (left,top-int(height * TEXT_Y_OFFSET_SCALE)),\n",
    "        fontFace = cv2.FONT_HERSHEY_PLAIN,\n",
    "        fontScale = min(width,height)* FONT_SCALE,\n",
    "        thickness = math.ceil(min(width,height)* THICKNESS_SCALE),\n",
    "        color = (255,255,255)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image,boxes,classnames,scores):\n",
    "    boxesidx = tf.image.non_max_suppression(boxes,scores,max_output_size = 4, iou_threshold = 0.5,score_threshold = 0.1)\n",
    "#     for i in range(len(boxes)):\n",
    "    for i in boxesidx:\n",
    "        ymin,xmin,ymax,xmax = tuple(boxes[i])\n",
    "        classname = classnames[i].decode(\"ascii\")\n",
    "        if classname in colorcodes.keys():\n",
    "            color = colorcodes[classname]\n",
    "        else:\n",
    "            c1 = random.randrange(0,255,30)\n",
    "            c2 = random.randrange(0,255,25)\n",
    "            c3 = random.randrange(0,255,50)\n",
    "            colorcodes.update({classname: (c1,c2,c3)})\n",
    "            color = colorcodes[classname]\n",
    "        namewithscore = \"{}:{}\".format(classname,int(100*scores[i]))\n",
    "        drawbox(image,ymin,xmin,ymax,xmax,namewithscore,color)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and processed successfully.\n",
      "tf.Tensor(\n",
      "[b'Human face' b'Man' b'Clothing' b'Human eye' b'Human nose' b'Human hair'\n",
      " b'Human eye' b'Shirt' b'Human ear' b'Human eye' b'Human arm'\n",
      " b'Human beard' b'Human eye' b'Human nose' b'Human hair' b'Human eye'\n",
      " b'Shirt' b'Human eye' b'Human ear' b'Human head' b'Human eye'\n",
      " b'Human mouth' b'Human hair' b'Human mouth' b'Human eye' b'Human arm'\n",
      " b'Human hair' b'Human ear' b'Person' b'Human hair' b'Human hair'\n",
      " b'Human eye' b'Human nose' b'Shirt' b'Human nose' b'Human mouth'\n",
      " b'Human hair' b'Shirt' b'Human nose' b'Human ear' b'Human hair'\n",
      " b'Human hair' b'Human hair' b'Human hair' b'Shirt' b'Man' b'Human nose'\n",
      " b'Human nose' b'Human mouth' b'Human hair' b'Clothing' b'Human hair'\n",
      " b'Human eye' b'Human hair' b'Human hair' b'Shirt' b'Human eye'\n",
      " b'Human hair' b'Human hair' b'Clothing' b'Fashion accessory' b'Human arm'\n",
      " b'Human hair' b'Human hair' b'Human beard' b'Human nose' b'Human hair'\n",
      " b'Human hair' b'Human hair' b'Human eye' b'Human ear' b'Human arm' b'Tie'\n",
      " b'Fashion accessory' b'Fashion accessory' b'Tie' b'Human ear' b'Clothing'\n",
      " b'Human mouth' b'Human eye' b'Human eye' b'Tie' b'Human hair'\n",
      " b'Human hair' b'Human ear' b'Shirt' b'Human hair' b'Human ear'\n",
      " b'Fashion accessory' b'Human eye' b'Window' b'Human beard'\n",
      " b'Fashion accessory' b'Human eye' b'Fashion accessory' b'Human arm'\n",
      " b'Human eye' b'Fashion accessory' b'Fashion accessory' b'Human hair'], shape=(100,), dtype=string)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tk().withdraw()\n",
    "\n",
    "# Open a file dialog to select an image\n",
    "file_path = filedialog.askopenfilename(\n",
    "    title=\"Select an Image\",\n",
    "    filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg;*.bmp\")]\n",
    ")\n",
    "\n",
    "if file_path:\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.resize(image, (800, 600))\n",
    "    image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    converted_img = tf.image.convert_image_dtype(image2, tf.float32)[tf.newaxis, ...]\n",
    "    print(\"Image loaded and processed successfully.\")\n",
    "else:\n",
    "    print(\"No file selected.\")\n",
    "\n",
    "detection=model(converted_img)\n",
    "\n",
    "print(detection[\"detection_class_entities\"])\n",
    "\n",
    "\n",
    "result={key:value.numpy() for key,value in detection.items()}\n",
    "imagewithboxes=draw(image,result[\"detection_boxes\"],result[\"detection_class_entities\"],result[  \"detection_scores\"])\n",
    "cv2.imshow(\"image\",imagewithboxes)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
